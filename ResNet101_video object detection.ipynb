{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from PIL import Image, ImageDraw, ImageColor, ImageFont, ImageOps\n",
    "from IPython.display import Image as IPyImage\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_MODELS = {\n",
    "    'CenterNet HourGlass104 512x512':\n",
    "    'https://tfhub.dev/tensorflow/centernet/hourglass_512x512/1',\n",
    "    'CenterNet HourGlass104 Keypoints 512x512':\n",
    "    'https://tfhub.dev/tensorflow/centernet/hourglass_512x512_kpts/1',\n",
    "    'CenterNet HourGlass104 1024x1024':\n",
    "    'https://tfhub.dev/tensorflow/centernet/hourglass_1024x1024/1',\n",
    "    'CenterNet HourGlass104 Keypoints 1024x1024':\n",
    "    'https://tfhub.dev/tensorflow/centernet/hourglass_1024x1024_kpts/1',\n",
    "    'CenterNet Resnet50 V1 FPN 512x512':\n",
    "    'https://tfhub.dev/tensorflow/centernet/resnet50v1_fpn_512x512/1',\n",
    "    'CenterNet Resnet50 V1 FPN Keypoints 512x512':\n",
    "    'https://tfhub.dev/tensorflow/centernet/resnet50v1_fpn_512x512_kpts/1',\n",
    "    'CenterNet Resnet101 V1 FPN 512x512':\n",
    "    'https://tfhub.dev/tensorflow/centernet/resnet101v1_fpn_512x512/1',\n",
    "    'CenterNet Resnet50 V2 512x512':\n",
    "    'https://tfhub.dev/tensorflow/centernet/resnet50v2_512x512/1',\n",
    "    'CenterNet Resnet50 V2 Keypoints 512x512':\n",
    "    'https://tfhub.dev/tensorflow/centernet/resnet50v2_512x512_kpts/1',\n",
    "    'EfficientDet D0 512x512':\n",
    "    'https://tfhub.dev/tensorflow/efficientdet/d0/1',\n",
    "    'EfficientDet D1 640x640':\n",
    "    'https://tfhub.dev/tensorflow/efficientdet/d1/1',\n",
    "    'EfficientDet D2 768x768':\n",
    "    'https://tfhub.dev/tensorflow/efficientdet/d2/1',\n",
    "    'EfficientDet D3 896x896':\n",
    "    'https://tfhub.dev/tensorflow/efficientdet/d3/1',\n",
    "    'EfficientDet D4 1024x1024':\n",
    "    'https://tfhub.dev/tensorflow/efficientdet/d4/1',\n",
    "    'EfficientDet D5 1280x1280':\n",
    "    'https://tfhub.dev/tensorflow/efficientdet/d5/1',\n",
    "    'EfficientDet D6 1280x1280':\n",
    "    'https://tfhub.dev/tensorflow/efficientdet/d6/1',\n",
    "    'EfficientDet D7 1536x1536':\n",
    "    'https://tfhub.dev/tensorflow/efficientdet/d7/1',\n",
    "    'SSD MobileNet v2 320x320':\n",
    "    'https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2',\n",
    "    'SSD MobileNet V1 FPN 640x640':\n",
    "    'https://tfhub.dev/tensorflow/ssd_mobilenet_v1/fpn_640x640/1',\n",
    "    'SSD MobileNet V2 FPNLite 320x320':\n",
    "    'https://tfhub.dev/tensorflow/ssd_mobilenet_v2/fpnlite_320x320/1',\n",
    "    'SSD MobileNet V2 FPNLite 640x640':\n",
    "    'https://tfhub.dev/tensorflow/ssd_mobilenet_v2/fpnlite_640x640/1',\n",
    "    'SSD ResNet50 V1 FPN 640x640 (RetinaNet50)':\n",
    "    'https://tfhub.dev/tensorflow/retinanet/resnet50_v1_fpn_640x640/1',\n",
    "    'SSD ResNet50 V1 FPN 1024x1024 (RetinaNet50)':\n",
    "    'https://tfhub.dev/tensorflow/retinanet/resnet50_v1_fpn_1024x1024/1',\n",
    "    'SSD ResNet101 V1 FPN 640x640 (RetinaNet101)':\n",
    "    'https://tfhub.dev/tensorflow/retinanet/resnet101_v1_fpn_640x640/1',\n",
    "    'SSD ResNet101 V1 FPN 1024x1024 (RetinaNet101)':\n",
    "    'https://tfhub.dev/tensorflow/retinanet/resnet101_v1_fpn_1024x1024/1',\n",
    "    'SSD ResNet152 V1 FPN 640x640 (RetinaNet152)':\n",
    "    'https://tfhub.dev/tensorflow/retinanet/resnet152_v1_fpn_640x640/1',\n",
    "    'SSD ResNet152 V1 FPN 1024x1024 (RetinaNet152)':\n",
    "    'https://tfhub.dev/tensorflow/retinanet/resnet152_v1_fpn_1024x1024/1',\n",
    "    'Faster R-CNN ResNet50 V1 640x640':\n",
    "    'https://tfhub.dev/tensorflow/faster_rcnn/resnet50_v1_640x640/1',\n",
    "    'Faster R-CNN ResNet50 V1 1024x1024':\n",
    "    'https://tfhub.dev/tensorflow/faster_rcnn/resnet50_v1_1024x1024/1',\n",
    "    'Faster R-CNN ResNet50 V1 800x1333':\n",
    "    'https://tfhub.dev/tensorflow/faster_rcnn/resnet50_v1_800x1333/1',\n",
    "    'Faster R-CNN ResNet101 V1 640x640':\n",
    "    'https://tfhub.dev/tensorflow/faster_rcnn/resnet101_v1_640x640/1',\n",
    "    'Faster R-CNN ResNet101 V1 1024x1024':\n",
    "    'https://tfhub.dev/tensorflow/faster_rcnn/resnet101_v1_1024x1024/1',\n",
    "    'Faster R-CNN ResNet101 V1 800x1333':\n",
    "    'https://tfhub.dev/tensorflow/faster_rcnn/resnet101_v1_800x1333/1',\n",
    "    'Faster R-CNN ResNet152 V1 640x640':\n",
    "    'https://tfhub.dev/tensorflow/faster_rcnn/resnet152_v1_640x640/1',\n",
    "    'Faster R-CNN ResNet152 V1 1024x1024':\n",
    "    'https://tfhub.dev/tensorflow/faster_rcnn/resnet152_v1_1024x1024/1',\n",
    "    'Faster R-CNN ResNet152 V1 800x1333':\n",
    "    'https://tfhub.dev/tensorflow/faster_rcnn/resnet152_v1_800x1333/1',\n",
    "    'Faster R-CNN Inception ResNet V2 640x640':\n",
    "    'https://tfhub.dev/tensorflow/faster_rcnn/inception_resnet_v2_640x640/1',\n",
    "    'Faster R-CNN Inception ResNet V2 1024x1024':\n",
    "    'https://tfhub.dev/tensorflow/faster_rcnn/inception_resnet_v2_1024x1024/1',\n",
    "    'Mask R-CNN Inception ResNet V2 1024x1024':\n",
    "    'https://tfhub.dev/tensorflow/mask_rcnn/inception_resnet_v2_1024x1024/1',\n",
    "    'yolo-v5-tflite/tflite_model':\n",
    "    'https://tfhub.dev/neso613/lite-model/yolo-v5-tflite/tflite_model/1',\n",
    "    'yolo-cppe5-lite':\n",
    "    'https://tfhub.dev/rishit-dagli/lite-model/yolo-cppe5-lite/default/1'\n",
    "}\n",
    "\n",
    "## total clases\n",
    "classes = {1: 'person', 2: 'bicycle', 3: 'car', 4: 'motorcycle', 5: 'airplane', 6: 'bus', 7: 'train', 8: 'truck', 9: 'boat', 10: 'traffic light', 11: 'fire hydrant', 13: 'stop sign', 14: 'parking meter', 15: 'bench', 16: 'bird', 17: 'cat', 18: 'dog', 19: 'horse', 20: 'sheep', 21: 'cow', 22: 'elephant', 23: 'bear', 24: 'zebra', 25: 'giraffe', 27: 'backpack', 28: 'umbrella', 31: 'handbag', 32: 'tie', 33: 'suitcase', 34: 'frisbee', 35: 'skis', 36: 'snowboard', 37: 'sports ball', 38: 'kite', 39: 'baseball bat', 40: 'baseball glove', 41: 'skateboard', 42: 'surfboard', 43: 'tennis racket', 44: 'bottle', 46: 'wine glass', 47: 'cup', 48: 'fork', 49: 'knife', 50: 'spoon', 51: 'bowl', 52: 'banana', 53: 'apple', 54: 'sandwich', 55: 'orange', 56: 'broccoli', 57: 'carrot', 58: 'hot dog', 59: 'pizza', 60: 'donut', 61: 'cake', 62: 'chair', 63: 'couch', 64: 'potted plant', 65: 'bed', 67: 'dining table', 70: 'toilet', 72: 'tv', 73: 'laptop', 74: 'mouse', 75: 'remote', 76: 'keyboard', 77: 'cell phone', 78: 'microwave', 79: 'oven', 80: 'toaster', 81: 'sink', 82: 'refrigerator', 84: 'book', 85: 'clock', 86: 'vase', 87: 'scissors', 88: 'teddy bear', 89: 'hair drier', 90: 'toothbrush'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected model:Faster R-CNN ResNet101 V1 640x640\n",
      "Model Handle at TensorFlow Hub: https://tfhub.dev/tensorflow/faster_rcnn/resnet101_v1_640x640/1\n",
      "Model loaded\n"
     ]
    }
   ],
   "source": [
    "detector = hub.load('https://tfhub.dev/rishit-dagli/yolo-cppe5/1')\n",
    "print('Model loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.saved_model.load.Loader._recreate_base_user_object.<locals>._UserObject at 0x25b6c11dc90>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://tfhub.dev/tensorflow/faster_rcnn/resnet101_v1_640x640/1'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_handle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bounding_box_on_image(image,\n",
    "                               ymin,\n",
    "                               xmin,\n",
    "                               ymax,\n",
    "                               xmax,\n",
    "                               color,\n",
    "                               font,\n",
    "                               thickness=4,\n",
    "                               display_str_list=()):\n",
    "    \"\"\"Adds a bounding box to an image.\"\"\"\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    im_width, im_height = image.size\n",
    "    (left, right, top, bottom) = (xmin * im_width, xmax * im_width,\n",
    "                                  ymin * im_height, ymax * im_height)\n",
    "    draw.line([(left, top), (left, bottom), (right, bottom), (right, top),\n",
    "               (left, top)],\n",
    "              width=thickness,\n",
    "              fill=color)\n",
    "\n",
    "    # If the total height of the display strings added to the top of the bounding\n",
    "    # box exceeds the top of the image, stack the strings below the bounding box\n",
    "    # instead of above.\n",
    "    display_str_heights = [font.getsize(ds)[1] for ds in display_str_list]\n",
    "    # Each display_str has a top and bottom margin of 0.05x.\n",
    "    total_display_str_height = (1 + 2 * 0.05) * sum(display_str_heights)\n",
    "\n",
    "    if top > total_display_str_height:\n",
    "        text_bottom = top\n",
    "    else:\n",
    "        text_bottom = top + total_display_str_height\n",
    "    # Reverse list and print from bottom to top.\n",
    "    for display_str in display_str_list[::-1]:\n",
    "        text_width, text_height = font.getsize(display_str)\n",
    "        margin = np.ceil(0.05 * text_height)\n",
    "        draw.rectangle([(left, text_bottom - text_height - 2 * margin),\n",
    "                        (left + text_width, text_bottom)],\n",
    "                       fill=color)\n",
    "        draw.text((left + margin, text_bottom - text_height - margin),\n",
    "                  display_str,\n",
    "                  fill=\"black\",\n",
    "                  font=font)\n",
    "        text_bottom -= text_height - 2 * margin\n",
    "\n",
    "\n",
    "def draw_boxes(image, boxes, class_names, scores, max_boxes=10, min_score=0.45):\n",
    "    \"\"\"Overlay labeled boxes on an image with formatted scores and label names.\"\"\"\n",
    "    colors = list(ImageColor.colormap.values())\n",
    "\n",
    "    try:\n",
    "        font = ImageFont.truetype(\n",
    "            \"/usr/share/fonts/truetype/liberation/LiberationSansNarrow-Regular.ttf\",\n",
    "            25)\n",
    "    except IOError:\n",
    "        #print(\"Font not found, using default font.\")\n",
    "        font = ImageFont.load_default()\n",
    "\n",
    "    for i in range(min(boxes.shape[0], max_boxes)):\n",
    "        if scores[i] >= min_score:\n",
    "            ymin, xmin, ymax, xmax = tuple(boxes[i])\n",
    "            if not(i < len(class_names) and i < len(scores)):\n",
    "                continue\n",
    "            display_str = \"{}: {}%\".format(class_names[i],\n",
    "                                           int(100 * scores[i]))\n",
    "            color = colors[hash(class_names[i]) % len(colors)]\n",
    "            image_pil = Image.fromarray(np.uint8(image)).convert(\"RGB\")\n",
    "            draw_bounding_box_on_image(image_pil,\n",
    "                                       ymin,\n",
    "                                       xmin,\n",
    "                                       ymax,\n",
    "                                       xmax,\n",
    "                                       color,\n",
    "                                       font,\n",
    "                                       display_str_list=[display_str])\n",
    "            np.copyto(image, np.array(image_pil))\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_detector(detector, image, classes):\n",
    "\n",
    "    converted_img = np.expand_dims(image, 0)\n",
    "\n",
    "    start_time = time.time()\n",
    "    result = detector(converted_img)\n",
    "    end_time = time.time()\n",
    "\n",
    "    result = {key: value.numpy() for key, value in result.items()}\n",
    "    print(\"Inference time: \", end_time - start_time)\n",
    "\n",
    "    classes_names = [classes[i]\n",
    "                     for i in result[\"detection_classes\"][0] if i in classes]\n",
    "\n",
    "    detection_boxes = result[\"detection_boxes\"][0]\n",
    "    detection_scores = result[\"detection_scores\"][0]\n",
    "    image_with_boxes = draw_boxes(image, detection_boxes,\n",
    "                                  classes_names, detection_scores)\n",
    "\n",
    "    return image_with_boxes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "# Load the webcam handler\n",
    "cap = cv2.VideoCapture('highway_480p.mp4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret, frame = cap.read()\n",
    "ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_FRAMES = 100\n",
    "processed_imgs = []\n",
    "for i in range(NUM_FRAMES):\n",
    "    # Load frame from the camera\n",
    "    ret, frame = cap.read()\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    image_boxes = run_detector(detector, frame, classes)\n",
    "    img = Image.fromarray(np.uint8(image_boxes))#.convert('RGB')\n",
    "    processed_imgs.append(img)\n",
    "    cv2.imshow(\"test\", cv2.cvtColor(image_boxes, cv2.COLOR_BGR2RGB))\n",
    "    cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_imgs[0].save('web_cam_480.gif',\n",
    "                       format='GIF',\n",
    "                       append_images=processed_imgs[1:],\n",
    "                       save_all=True,\n",
    "                       duration=100,\n",
    "                       loop=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IPyImage('web_cam_480.gif', format='png', width=15 * 40, height=3 * 40) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
